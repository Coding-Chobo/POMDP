# hybrid_pf_lstm_pruning.py
# ------------------------------------------------------------
# íŒŒí‹°í´ ìš”ì•½ + GRU(=LSTM ê³„ì—´) í•˜ì´ë¸Œë¦¬ë“œ ì •ì±… + ì‹œê°í™”ìš© pruning
# ------------------------------------------------------------
import math, random, json, os
from dataclasses import dataclass
from typing import Tuple, List, Dict, Optional

import numpy as np
import networkx as nx
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F

# ==========================
# ğŸ”§ ì„¤ì •
# ==========================
@dataclass
class HybridConfig:
    grid_size: int = 20
    # Particle Filter
    pf_num_particles: int = 800
    pf_resample_every: int = 3
    pf_process_noise: float = 0.75    # ì˜ˆì¸¡ì‹œ jitter í”½ì…€ í‘œì¤€í¸ì°¨
    pf_likelihood_ang_sigma: float = 1.0
    pf_likelihood_dist_sigma: float = 1.0
    pf_topk_modes: int = 3
    # DRQN / Training
    obs_dim_onehot: int = (16 + 10 + 1 + 8 + 4 + 2)  # ang16 + dist10 + far1 + face8 + coin4 + see2
    belief_feat_dim: int = 2 + 1 + 1 + 2*3  # mean(dx,dy)+ mean_dist + entropy + topK( (dx,dy)*K )
    hidden: int = 128
    n_actions: int = 15
    gamma: float = 0.997
    lr: float = 3e-4
    burn_in: int = 20
    unroll: int = 40
    target_update: int = 2000
    # Replay
    replay_capacity: int = 50_000
    batch_size: int = 16
    seq_len: int = 60          # burn_in+unrollê³¼ ë™ì¼í•˜ê²Œ ì“°ëŠ” ê±¸ ê¶Œì¥
    # Epsilon (í–‰ë™ íƒí—˜)
    eps_start: float = 0.2
    eps_final: float = 0.02
    eps_decay: float = 0.9995
    # Viz & pruning (ì‹œê°í™” ì‚¬ë³¸ì—ë§Œ ì ìš©)
    viz_min_edge_count: int = 3
    viz_topk_per_node: int = 2
    viz_k_core: int = 2
    viz_keep_largest: bool = True

# ============================================================
# ğŸ§  ê´€ì°° â†’ ì›-í•« ë²¡í„° (ë„¤ env.observe() ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
#   obs = (ang_bin, dist_bin, far(bool), my_face_bin, coin_dist_bin, see_coin_flag)
# ============================================================
def obs_to_onehot(obs: Tuple[int,int,bool,int,int,int]) -> np.ndarray:
    ang, dist, far, face, coin_bin, see = obs
    v = []
    def oh(i, n):
        a = np.zeros(n, dtype=np.float32); a[int(i)%n] = 1.0; return a
    v.append(oh(ang, 16))            # 16
    v.append(oh(9 if far else dist, 10))  # 10 (farë©´ dist=9 ìŠ¬ë¡¯)
    v.append(np.array([1.0 if far else 0.0], dtype=np.float32))  # 1
    v.append(oh(face, 8))            # 8
    v.append(oh(coin_bin, 4))        # 4
    v.append(oh(see, 2))             # 2
    return np.concatenate(v, axis=0) # ì´ 41

# ============================================================
# ğŸ¯ íŒŒí‹°í´ í•„í„° (ìƒëŒ€ì˜ "ìƒëŒ€ì¢Œí‘œ" (dx,dy)ë§Œ ì¶”ì )
#   - ì—ì´ì „íŠ¸ì˜ ê´€ì ì—ì„œ ìƒëŒ€ê¹Œì§€ì˜ ìƒëŒ€ì¢Œí‘œ ë¶„í¬ë¥¼ ì…ìë¡œ ìœ ì§€
#   - ê´€ì°° likelihoodë¡œ ê°€ì¤‘ì¹˜ ê°±ì‹ 
#   - ìš”ì•½í†µê³„(í‰ê· /ê±°ë¦¬/ì—”íŠ¸ë¡œí”¼/Top-K ëª¨ë“œ) ì‚°ì¶œ
# ============================================================
class ParticleFilter:
    def __init__(self, cfg: HybridConfig, fov_radius: int = 10, seed: int = 0):
        self.cfg = cfg
        self.n = cfg.grid_size
        self.fov = fov_radius
        self.rng = np.random.default_rng(seed)
        self.num = cfg.pf_num_particles
        self.p = None          # (N,2) dx,dy
        self.w = None          # (N,)
        self._steps = 0
        self.reset()

    def reset(self):
        # ì´ˆê¸° ë¶„í¬: ì›ì  ì£¼ë³€ ë„“ê²Œ (ìƒëŒ€ì¢Œí‘œ ëª¨ë¥´ë¯€ë¡œ ê· ì¼/ê°€ìš°ì‹œì•ˆ)
        low = -self.n + 1; high = self.n - 1
        self.p = self.rng.integers(low, high+1, size=(self.num, 2)).astype(np.float32)
        self.w = np.ones(self.num, dtype=np.float32) / self.num
        self._steps = 0

    def predict(self, my_move: Tuple[int,int]=(0,0)):
        # ìƒëŒ€ ì¢Œí‘œ = ìƒëŒ€ - ë‚˜
        # ë‚´ê°€ (dx,dy)ë¡œ ì›€ì§ì˜€ìœ¼ë©´ ìƒëŒ€ì¢Œí‘œëŠ” (-dx, -dy)ë§Œí¼ ë³€í•¨
        dx, dy = my_move
        self.p[:,0] -= dx
        self.p[:,1] -= dy
        # ìƒëŒ€ì˜ ë¯¸ì§€ ì´ë™(ì•½í•œ ëœë¤ ì›Œí¬)
        noise = self.cfg.pf_process_noise
        jitter = self.rng.normal(0.0, noise, size=self.p.shape).astype(np.float32)
        self.p += jitter
        # ê²½ê³„ í´ë¨í”„
        self.p[:,0] = np.clip(self.p[:,0], -self.n+1, self.n-1)
        self.p[:,1] = np.clip(self.p[:,1], -self.n+1, self.n-1)
        self._steps += 1

    def _angle_bin16(self, dx, dy):
        if dx==0 and dy==0: return 0
        a = math.atan2(dy, dx)
        if a<0: a += 2*math.pi
        bin_size = 2*math.pi/16
        return int((a + bin_size/2)//bin_size) % 16

    def _dist_bin10(self, d):
        # ë„¤ ì½”ë“œì˜ dist_binê³¼ 9=farë¥¼ ë§ì¶”ë ¤ë©´ farëŠ” likelihoodì—ì„œ ë”°ë¡œ ì²˜ë¦¬
        cuts = [1,2,4,6,9,13,18,24]  # 0..8 (9ëŠ” far)
        for i,c in enumerate(cuts):
            if d<=c: return i
        return len(cuts) # 8

    def weight_update(self, obs: Tuple[int,int,bool,int,int,int]):
        ang, dist, far, face, coin_bin, see = obs
        # íŒŒí‹°í´ì˜ ê´€ì°° ì˜ˆì¸¡ì¹˜ ê³„ì‚°
        dx = self.p[:,0]; dy = self.p[:,1]
        dist_mh = np.abs(dx) + np.abs(dy)
        pred_far = dist_mh > self.fov
        pred_ang = np.array([self._angle_bin16(dx[i], dy[i]) if not pred_far[i] else 0
                             for i in range(self.num)], dtype=np.int32)
        pred_dist = np.array([9 if pred_far[i] else self._dist_bin10(dist_mh[i])
                              for i in range(self.num)], dtype=np.int32)

        # ë‹¨ìˆœ ê°€ìš°ì‹œì•ˆ ìœ ì‚¬ë„(ê°ë„ëŠ” ìˆœí™˜ê±°ë¦¬, ê±°ë¦¬binì€ L2)
        ang_sigma = self.cfg.pf_likelihood_ang_sigma
        dist_sigma = self.cfg.pf_likelihood_dist_sigma

        def ang_circ_delta(a,b):  # 16ê°œ ì›í˜• ê±°ë¦¬
            d = abs((a-b)%16)
            return min(d, 16-d)

        ang_err = np.array([ang_circ_delta(pred_ang[i], ang) for i in range(self.num)], dtype=np.float32)
        dist_err = np.abs(pred_dist - (9 if far else dist)).astype(np.float32)

        like_ang = np.exp(-(ang_err**2)/(2*(ang_sigma**2)))
        like_dst = np.exp(-(dist_err**2)/(2*(dist_sigma**2)))

        like = like_ang * like_dst + 1e-8
        self.w *= like
        s = self.w.sum()
        if s<=0:
            # ìˆ«ì ë¶ˆì•ˆì • ì‹œ ì¬ì´ˆê¸°í™”(í¬ê·€): ê· ì¼ ì¬ì‹œì‘
            self.w[:] = 1.0/self.num
        else:
            self.w /= s

        # ì£¼ê¸°ì ìœ¼ë¡œ ë¦¬ìƒ˜í”Œ
        if (self._steps % self.cfg.pf_resample_every) == 0:
            self._systematic_resample()

    def _systematic_resample(self):
        N = self.num
        positions = (np.arange(N) + self.rng.random())/N
        cumsum = np.cumsum(self.w)
        indexes = np.zeros(N, dtype=np.int32)
        i = j = 0
        while i < N:
            if positions[i] < cumsum[j]:
                indexes[i] = j
                i += 1
            else:
                j += 1
        self.p = self.p[indexes]
        self.w = np.ones(N, dtype=np.float32)/N

    def summarize(self, topk:int=None) -> np.ndarray:
        if topk is None: topk = self.cfg.pf_topk_modes
        # í‰ê· /ë¶„ì‚°/ì—”íŠ¸ë¡œí”¼
        mean = (self.w[:,None]*self.p).sum(axis=0)   # (2,)
        var = (self.w[:,None]*((self.p-mean)**2)).sum(axis=0).sum()  # trace approx
        mean_dist = (np.abs(self.p).sum(axis=1)*self.w).sum()  # E[manhattan]
        # ì—”íŠ¸ë¡œí”¼(ê°€ì¤‘ì¹˜ ë¶„í¬)
        w = np.clip(self.w, 1e-12, 1.0)
        entropy = float(-(w*np.log(w)).sum() / math.log(len(w)))  # [0,1] ì •ê·œí™” ê·¼ì‚¬

        # Top-K ëª¨ë“œ(ê°€ì¤‘ì¹˜ ìƒìœ„ K íŒŒí‹°í´ ìœ„ì¹˜)
        idx = np.argsort(-self.w)[:topk]
        top = self.p[idx]  # (K,2)

        # ìŠ¤ì¼€ì¼ ì •ê·œí™”(ëŒ€ëµì ì¸ [-1,1])
        s = float(self.n)
        feats = [
            mean[0]/s, mean[1]/s,
            mean_dist/(2*s),            # manhattan ê±°ë¦¬ ì •ê·œí™”
            min(1.0, var/(s*s)),        # ëŒ€ì¶© ìŠ¤ì¼€ì¼
            entropy
        ]
        for i in range(topk):
            dx,dy = (top[i]/s) if i < len(top) else (np.array([0.0,0.0]))
            feats.extend([float(dx), float(dy)])
        # ë¶€ì¡±í•œ KëŠ” 0ìœ¼ë¡œ ì±„ì›Œì„œ ê³ ì •ê¸¸ì´
        while len(feats) < (2 + 1 + 1 + 2*topk):  # mean2 + mean_dist1 + var1 + (dx,dy)*K
            feats.extend([0.0, 0.0])
        return np.array(feats, dtype=np.float32)

# ============================================================
# ğŸ§© DRQN(ì—¬ê¸°ì„œëŠ” GRU) + Dueling Head
#   ì…ë ¥ = ê´€ì°° ì›-í•« + íŒŒí‹°í´ ìš”ì•½
# ============================================================
class DRQN(nn.Module):
    def __init__(self, in_dim: int, hidden: int, n_actions: int):
        super().__init__()
        self.enc = nn.Sequential(
            nn.Linear(in_dim, 128), nn.ReLU(),
            nn.Linear(128, 128), nn.ReLU()
        )
        self.gru = nn.GRU(128, hidden, batch_first=True)
        # Dueling
        self.val = nn.Sequential(nn.Linear(hidden, 128), nn.ReLU(), nn.Linear(128, 1))
        self.adv = nn.Sequential(nn.Linear(hidden, 128), nn.ReLU(), nn.Linear(128, n_actions))

    def forward(self, x_seq: torch.Tensor, h0: Optional[torch.Tensor]=None):
        # x_seq: [B,T,in_dim]
        z = self.enc(x_seq)
        out, hT = self.gru(z, h0)   # out: [B,T,H]
        V = self.val(out)           # [B,T,1]
        A = self.adv(out)           # [B,T,A]
        Q = V + (A - A.mean(dim=-1, keepdim=True))
        return Q, hT

# ============================================================
# ğŸ§³ ì‹œí€€ìŠ¤ ë¦¬í”Œë ˆì´ ë²„í¼ (ê°„ë‹¨ êµ¬í˜„: ì—í”¼ì†Œë“œ ë‹¨ìœ„ë¡œ ì €ì¥)
# ============================================================
class SeqReplay:
    def __init__(self, capacity:int, seq_len:int):
        self.capacity = capacity
        self.seq_len = seq_len
        self.data = []  # ê° í•­ëª©ì€ dict{obs, belief, act, rew, done}
        self.ptr = 0

    def push_episode(self, traj: Dict[str, np.ndarray]):
        # traj ê° í‚¤: (T, feat) í˜¹ì€ (T,)
        if len(self.data) < self.capacity:
            self.data.append(traj)
        else:
            self.data[self.ptr] = traj
            self.ptr = (self.ptr + 1) % self.capacity

    def sample_batch(self, batch:int, burn_in:int, unroll:int):
        # ì—í”¼ì†Œë“œì—ì„œ ëœë¤ ì‹œì‘ ìœ„ì¹˜ë¥¼ ë½‘ì•„ [burn_in+unroll] ê¸¸ì´ë¡œ ìŠ¬ë¼ì´ìŠ¤
        B = batch
        seqs = random.sample(self.data, B)
        out = []
        for ep in seqs:
            T = len(ep["act"])
            if T < (burn_in+unroll+1):   # íƒ€ê¹ƒ s_{t+unroll}ê¹Œì§€ í•„ìš”
                # ì§§ìœ¼ë©´ íŒ¨ìŠ¤ (ì‹¤ì „ì—” íŒ¨ë”©/ë§ˆìŠ¤í‚¹ êµ¬í˜„ ê¶Œì¥)
                return None
            start = random.randint(0, T - (burn_in+unroll+1))
            sl = slice(start, start+burn_in+unroll+1)  # +1 for bootstrap state
            item = {k: v[sl] for k,v in ep.items()}
            out.append(item)
        return out

# ============================================================
# ğŸ§ª Îµ-greedy í–‰ë™ ì„ íƒ
# ============================================================
def select_action_eps_greedy(q_t: torch.Tensor, eps: float) -> int:
    # q_t: [1,1,A]
    if random.random() < eps:
        return random.randrange(q_t.shape[-1])
    return int(torch.argmax(q_t, dim=-1).item())

# ============================================================
# ğŸ” ì‹œê°í™” + í”„ë£¨ë‹ (ì‚¬ë³¸ì—ë§Œ ì ìš©)
# ============================================================
def prune_transitions_by_count_and_topk(G: nx.DiGraph,
                                        min_edge_count:int=3,
                                        topk_per_node:int=2) -> nx.DiGraph:
    H = nx.DiGraph()
    H.add_nodes_from(G.nodes(data=True))
    # ì—£ì§€ ê°€ì¤‘ì¹˜ëŠ” 'count' ì†ì„±ìœ¼ë¡œ ê¸°ëŒ€
    for u in G.nodes():
        nbrs = []
        for v in G.successors(u):
            c = G[u][v].get("count", 1)
            if c >= min_edge_count and u!=v:
                nbrs.append((v,c))
        nbrs.sort(key=lambda x: x[1], reverse=True)
        for v,c in nbrs[:topk_per_node]:
            H.add_edge(u, v, count=c)
    return H

def prune_k_core_and_largest(G: nx.DiGraph, k_core:int=2, keep_largest:bool=True) -> nx.DiGraph:
    if G.number_of_nodes()==0: return G.copy()
    H = G.copy()
    if k_core is not None and k_core>0:
        try:
            H = nx.k_core(H, k=k_core)
        except nx.NetworkXError:
            pass
    if keep_largest and H.number_of_nodes()>0 and H.number_of_edges()>0:
        comps = sorted(nx.weakly_connected_components(H), key=len, reverse=True)
        H = H.subgraph(comps[0]).copy()
    return H

def draw_graph_pruned_copy(G: nx.DiGraph, save_path:str,
                           min_edge_count:int=3, topk_per_node:int=2,
                           k_core:int=2, keep_largest:bool=True,
                           title:str="Policy graph (pruned copy)"):
    # 1) ì›ë³¸ ë³´ì¡´
    H = prune_transitions_by_count_and_topk(G, min_edge_count, topk_per_node)
    H = prune_k_core_and_largest(H, k_core, keep_largest)

    # 2) ë ˆì´ì•„ì›ƒ/ê·¸ë¦¼
    if H.number_of_nodes()==0:
        plt.figure(figsize=(8,8)); plt.title(title+" (empty)")
        plt.axis('off'); plt.tight_layout(); plt.savefig(save_path, dpi=150); plt.close(); return

    pos = nx.kamada_kawai_layout(H)
    counts = [H[u][v].get("count",1) for u,v in H.edges()]
    nx.draw_networkx_edges(H, pos, alpha=0.18, arrows=False, width=[0.4+0.05*c for c in counts])
    nx.draw_networkx_nodes(H, pos, node_size=28, node_color="tab:blue", alpha=0.9)
    # (ì„ íƒ) ë¼ë²¨: ë„ˆë¬´ ë³µì¡í•´ì§€ë©´ ìƒëµ ê°€ëŠ¥
    # nx.draw_networkx_labels(H, pos, font_size=6)
    plt.title(title)
    plt.axis('off')
    plt.tight_layout(); plt.savefig(save_path, dpi=150); plt.close()
    return H

# ============================================================
# ğŸ”Œ í†µí•© í¬ì¸íŠ¸ (ì˜ˆì‹œ ëŸ¬ë„ˆ) â€” ë„¤ envë¥¼ ì—¬ê¸°ì— ì—°ê²°
#   - env.observe(True/False) : ê´€ì°° íŠœí”Œ
#   - env.step(a_chaser, a_evader, eval_mode=False) : í•œ ìŠ¤í… ì§„í–‰
#   - ACTIONS : í–‰ë™ ëª©ë¡ (ê¸¸ì´ = cfg.n_actions)
#   - ì•„ë˜ í•¨ìˆ˜ ë‘ ê°œë§Œ ë„¤ í”„ë¡œì íŠ¸ì— ë§ì¶° ì±„ì›Œ ë„£ìœ¼ë©´ ë!
# ============================================================
def my_move_delta_from_action(action_idx:int, my_face_bin:int) -> Tuple[int,int]:
    """ë‚´ê°€ ì´ í–‰ë™ì„ í–ˆì„ ë•Œ ìƒëŒ€ì¢Œí‘œê°€ ì–¼ë§ˆë‚˜ ë°”ë€ŒëŠ”ê°€ë¥¼ 'ë‚´ ì›€ì§ì„' ê¸°ì¤€ìœ¼ë¡œ ê·¼ì‚¬.
    - ë„¤ í”„ë¡œì íŠ¸ì—ì„œ ì •í™•í•œ ì´ë™(ì „ì§„/ìŠ¤íŠ¸ë ˆí”„/ë°±ìŠ¤í…)ì„ ê³„ì‚°í•  ìˆ˜ ìˆìœ¼ë©´ ì—¬ê¸°ë¥¼ ì¹˜í™˜í•˜ë©´ ëœë‹¤.
    - ê°„ë‹¨ ì˜ˆì‹œ: ì „ì§„(1) = ë‚´ í˜ì´ìŠ¤ ë°©í–¥ìœ¼ë¡œ (dx,dy)=vec, ìŠ¤íŠ¸ë ˆí”„/ë°±ìŠ¤í…ì€ ê·¸ì— ë§ì¶°."""
    # ì˜ˆì‹œ(ëŒ€ì¶©): FORWARD=6, STRAFE_L=7, STRAFE_R=8, BACKSTEP=9 (ë„¤ ACTIONS ì¸ë±ìŠ¤ì— ë§ê²Œ ìˆ˜ì •!)
    FORWARD, STRAFE_L, STRAFE_R, BACKSTEP = 6, 7, 8, 9
    # 8ë°©í–¥ ë‹¨ìœ„ ë²¡í„°
    DIRS8 = [(1,0),(1,1),(0,1),(-1,1),(-1,0),(-1,-1),(0,-1),(1,-1)]
    def vec(f): return DIRS8[f%8]
    dx,dy = 0,0
    if action_idx == FORWARD:
        vx,vy = vec(my_face_bin); dx,dy = vx,vy
    elif action_idx == STRAFE_L:
        vx,vy = vec((my_face_bin-2)%8); dx,dy = vx,vy
    elif action_idx == STRAFE_R:
        vx,vy = vec((my_face_bin+2)%8); dx,dy = vx,vy
    elif action_idx == BACKSTEP:
        vx,vy = vec((my_face_bin+4)%8); dx,dy = vx,vy
    else:
        dx,dy = 0,0
    return (dx,dy)

class HybridAgent:
    """íŒŒí‹°í´ ìš”ì•½ + GRU ê¸°ë°˜ DRQN ì •ì±… (Îµ-greedy)"""
    def __init__(self, cfg: HybridConfig, device="cpu"):
        self.cfg = cfg
        in_dim = cfg.obs_dim_onehot + cfg.belief_feat_dim
        self.net = DRQN(in_dim, cfg.hidden, cfg.n_actions).to(device)
        self.tgt = DRQN(in_dim, cfg.hidden, cfg.n_actions).to(device)
        self.tgt.load_state_dict(self.net.state_dict())
        self.optim = torch.optim.Adam(self.net.parameters(), lr=cfg.lr)
        self.device = device
        self.eps = cfg.eps_start
        self.step_count = 0

    def act(self, obs_vec: np.ndarray, belief_feat: np.ndarray, h: Optional[torch.Tensor]) -> Tuple[int, torch.Tensor]:
        x = torch.from_numpy(np.concatenate([obs_vec, belief_feat],axis=0)).float().to(self.device)
        x = x.view(1,1,-1)
        with torch.no_grad():
            q, h2 = self.net(x, h)
        a = select_action_eps_greedy(q, self.eps)
        return a, h2

    def decay_eps(self):
        self.eps = max(self.cfg.eps_final, self.eps*self.cfg.eps_decay)

    def train_on_batch(self, batch: List[Dict[str,np.ndarray]], gamma:float):
        if batch is None: return 0.0
        device = self.device
        B = len(batch); T = len(batch[0]["act"])  # T = burn+unroll+1
        burn, unroll = self.cfg.burn_in, self.cfg.unroll

        # (B,T,input_dim)
        def to_torch(name):
            X = np.stack([b[name] for b in batch], axis=0)  # (B,T,dim)
            return torch.from_numpy(X).float().to(device)

        x = to_torch("x")             # obs+belief
        a = torch.from_numpy(np.stack([b["act"] for b in batch],0)).long().to(device)  # (B,T)
        r = torch.from_numpy(np.stack([b["rew"] for b in batch],0)).float().to(device) # (B,T)
        d = torch.from_numpy(np.stack([b["done"] for b in batch],0)).float().to(device)# (B,T)

        # 1) burn-in: ìƒíƒœë§Œ ë°ìš°ê¸°
        with torch.no_grad():
            _, h = self.net(x[:, :burn, :])

        # 2) unroll: ì†ì‹¤ ê³„ì‚°
        q_on, _ = self.net(x[:, burn:-1, :], h)       # (B, unroll, A)
        with torch.no_grad():
            q_tgt, _ = self.tgt(x[:, burn+1:, :], h)  # ë‹¤ìŒ ìƒíƒœ (B, unroll, A)

        # Double DQN target
        with torch.no_grad():
            q_online_next, _ = self.net(x[:, burn+1:, :], h)
            a_star = torch.argmax(q_online_next, dim=-1)                 # (B,unroll)
            q_next = q_tgt.gather(-1, a_star.unsqueeze(-1)).squeeze(-1)  # (B,unroll)
            y = r[:, burn:-1] + gamma * (1.0 - d[:, burn:-1]) * q_next   # (B,unroll)

        q_sel = q_on.gather(-1, a[:, burn:-1].unsqueeze(-1)).squeeze(-1) # (B,unroll)
        loss = F.smooth_l1_loss(q_sel, y)

        self.optim.zero_grad()
        loss.backward()
        nn.utils.clip_grad_norm_(self.net.parameters(), 1.0)
        self.optim.step()

        self.step_count += 1
        if (self.step_count % self.cfg.target_update)==0:
            self.tgt.load_state_dict(self.net.state_dict())

        return float(loss.item())

# ============================================================
# ğŸ” ëŸ¬ë„ˆ: í•œ ì—í”¼ì†Œë“œ ì‹¤í–‰(ë°ëª¨ìš©) â€” ë„¤ envì— ë§ì¶° í˜¸ì¶œ
# ============================================================
def run_episode_with_pf_gru(env,
                            agent_self: HybridAgent,
                            agent_other: HybridAgent,
                            pf_self: ParticleFilter,
                            who: str = "chaser",
                            max_steps:int=1000):
    """í•œ ì—í”¼ì†Œë“œë¥¼ í‰ê°€ ëª¨ë“œë¡œ ì‹¤í–‰í•˜ê³ , ì‹œí€€ìŠ¤ë¥¼ ë¦¬í”Œë ˆì´ìš© í¬ë§·ìœ¼ë¡œ ë°˜í™˜."""
    assert who in ("chaser","evader")
    pf_self.reset()
    # ë¦¬í”Œë ˆì´ ì‹œí€€ìŠ¤ ëˆ„ì 
    xs, acts, rews, dones = [], [], [], []

    # RNN ì€ë‹‰ìƒíƒœ
    h = None
    # ì´ˆê¸° ê´€ì°°
    ob_s = env.observe(for_chaser=(who=="chaser"), eval_mode=True)
    obs_vec = obs_to_onehot(ob_s)
    belief_feat = pf_self.summarize()

    for t in range(max_steps):
        # í–‰ë™ ì„ íƒ
        a_s, h = agent_self.act(obs_vec, belief_feat, h)

        # ìƒëŒ€ëŠ” ì—¬ê¸°ì„  greedy(ë°ëª¨). ì‹¤ì œ í•™ìŠµì—ì„  ìƒëŒ€ë„ ìê¸° ì •ì±…/íƒí—˜ìœ¼ë¡œ.
        ob_o = env.observe(for_chaser=(who!="chaser"), eval_mode=True)
        obs_vec_o = obs_to_onehot(ob_o)
        belief_o = pf_self.summarize()  # ë°ëª¨ì—ì„  ê°™ì€ PFë¥¼ ì¬ì‚¬ìš©í•˜ê±°ë‚˜ ë³„ë„ PFë¥¼ ì“°ì
        with torch.no_grad():
            q_o, _ = agent_other.net(torch.from_numpy(np.concatenate([obs_vec_o, belief_o],0)).float().view(1,1,-1))
            a_o = int(torch.argmax(q_o, dim=-1).item())

        # í™˜ê²½ ìŠ¤í…
        if who=="chaser":
            _, (r_c, r_e), done = env.step(a_s, a_o, eval_mode=False)
            r = r_c
        else:
            _, (r_c, r_e), done = env.step(a_o, a_s, eval_mode=False)
            r = r_e

        # íŒŒí‹°í´ ì˜ˆì¸¡/ê°±ì‹ 
        # - ë‚´ ì›€ì§ì„ ë¸íƒ€(ìƒëŒ€ì¢Œí‘œì—ì„œ ë¹¼ì¤„ ê°’) ê³„ì‚°
        my_face_bin = ob_s[3]
        my_move = my_move_delta_from_action(a_s, my_face_bin)
        pf_self.predict(my_move=my_move)
        ob_s_next = env.observe(for_chaser=(who=="chaser"), eval_mode=True)
        pf_self.weight_update(ob_s_next)

        # ëˆ„ì (ë‹¤ìŒ ìŠ¤í… í•™ìŠµìš©)
        x = np.concatenate([obs_to_onehot(ob_s), pf_self.summarize()], axis=0)
        xs.append(x); acts.append(a_s); rews.append(r); dones.append(1.0 if done else 0.0)

        ob_s = ob_s_next
        obs_vec = obs_to_onehot(ob_s)
        belief_feat = pf_self.summarize()

        if done: break

    # numpyë¡œ ì •ë¦¬
    traj = {
        "x": np.stack(xs,0).astype(np.float32),
        "act": np.array(acts, dtype=np.int64),
        "rew": np.array(rews, dtype=np.float32),
        "done": np.array(dones, dtype=np.float32)
    }
    return traj

# ============================================================
# ğŸ“ˆ ì „ì´ ê·¸ë˜í”„ ìƒì„± + "ì‚¬ë³¸" í”„ë£¨ë‹ + ì €ì¥
#    (í•™ìŠµì—ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ!)
# ============================================================
def build_transition_graph_from_bins(bin_traj: List[int]) -> nx.DiGraph:
    G = nx.DiGraph()
    # ë…¸ë“œ ë“±ë¡
    for b in bin_traj:
        if b not in G: G.add_node(b)
    # ì—£ì§€ ì¹´ìš´íŠ¸
    for i in range(len(bin_traj)-1):
        u,v = bin_traj[i], bin_traj[i+1]
        if G.has_edge(u,v):
            G[u][v]["count"] += 1
        else:
            G.add_edge(u,v, count=1)
    return G

def save_graph_pruned_copy_png(G: nx.DiGraph, cfg: HybridConfig, path_png:str, title:str):
    draw_graph_pruned_copy(
        G, path_png,
        min_edge_count=cfg.viz_min_edge_count,
        topk_per_node=cfg.viz_topk_per_node,
        k_core=cfg.viz_k_core,
        keep_largest=cfg.viz_keep_largest,
        title=title
    )

# ============================================================
# ğŸ§· ë°ëª¨ ë©”ì¸ (ë„¤ í”„ë¡œì íŠ¸ì— ë§ê²Œ êµì²´í•´ì„œ ì‚¬ìš©)
# ============================================================
if __name__ == "__main__":
    # ---- ì—¬ê¸°ëŠ” ì„¤ëª…ìš© ë°ëª¨ ìŠ¤í…ì…ë‹ˆë‹¤. ----
    # ì‹¤ì œë¡œëŠ” ë„¤ í”„ë¡œì íŠ¸ì˜ env/ACTIONSë¥¼ import í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”.
    # from your_project import TwoAgentTagEnv, Config, BeliefIndexer, ACTIONS
    print("[hybrid] This is a plug-in module. Import and integrate into your training loop.")
